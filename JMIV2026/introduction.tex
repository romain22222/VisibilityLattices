    Visibility is a fundamental concept in computational geometry and
    digital topology, with applications ranging from computer vision
    (occlusions), geometric modeling (feature detection,
    geodesics) to computer graphics (path tracing,
    shadowmap). Visibility within polygons in the plane has been
    extensively studied in the litterature~\cite{ghosh:2007-book} and
    is still studied in higher dimensional
    spaces~\cite{orourke:2017-book}. The general problem has a high
    complexity. For instance, the 3d visibility complex between $n$
    spheres and occluding spheres has a complexity
    $O(n^4)$~\cite{durand:2002-tog}. Exact 3d visibility between
    polygons and occluding polygons is often cast into 5d Plücker
    space~\cite{nirenstein:2002-ewr}, which nicely represents 3d lines
    and their respective positions. The computational cost remains
    high even with decomposition into coarse cells for speed up
    (several days of computation for 1M triangles at the time).

    To increase efficiency, several authors have cast the
    visibility problem into a digital space, generally $\Z^3$ or its
    decomposition into cubical cells. Visibility is simplified as
    whether there is a connected digital straight line
    joining a pair of cells without occluding cell(s)
    (e.g.\ Soille~\cite{soille:1994-prl} uses Bresenham
    segments). Coeurjolly \emph{et al.}~\cite{coeurjolly:2004-prl}
    use a non-symmetric visibility definition and preimage
    computations to speed up these
    algorithms. Chica~\cite{chica:2008-spm} uses a half-cell erosion
    of the complementary space and Bresenham lines to decide
    visibility.

    We propose an algorithm that solves the following visibility
    problem: given a digital set $X \subset \Z^d$, two points $p,q$ of
    $X$ are \emph{visible} whenever the Euclidean straight line
    segment $\lbrack p,q \rbrack$ is never at chessboard distance
    ($\infty$-distance) greater or equal to $1$ from $X$. It is
    equivalent to the \emph{cotangency} of $p$ and $q$ in $X$, as
    formalized in~\cite{lachaud:2021-dgmm,lachaud:2022-jmiv}, and can
    be viewed as an inclusion problem between sets of lattice points
    in this form. Indeed, cells surounding $X$ can be encoded as
    lattice points (Khalimsky coding), as well as the cells covering
    lattice directions. The originality of our method is to encode
    subsets of lattice points as sets of integer intervals and to
    reduce all the inclusion problems as intersections and
    translations of integer intervals. For a given lattice vector
    $\mathbf{t}$, we solve the visibility of every pair of points
    $(p,p+\mathbf{t})$ of $X$. Global visibility is achieved by
    testing all sought directions within a given range, and is
    parallelized straightforwardly.

    We focus on solving efficiently this problem because it is crucial
    in computing geometric normals along digital surfaces that are
    aware of salient features. Indeed, 2d discrete tangent estimators
    based on tangency or discrete line segments have proven to be both
    sensitive to sharp corners and multigrid convergent on the
    boundary of digitized smooth shapes~\cite{feschet:1999-dgci,lachaud:2007-ivc,nguyen:2011-pr}.
    Many ad hoc methods have been proposed for tangent plane or normal
    estimation on 3d digital surfaces
    (e.g. \cite{fourey:2009-cg,charrier:2011-iwcia,Cuel:2014-dgci,Lachaud:2017-lnm,mareche:2024-ispr}).
    If two of these methods~\cite{Cuel:2014-dgci,Lachaud:2017-lnm}
    have been shown to be multigrid convergent on digitization of
    shapes with smooth boundary, their formulation intrinsically
    smoothes features, e.g.\ in contrast with the method of
    Mar{ê}ch{é} \emph{et al.}~\cite{mareche:2024-ispr}, whose
    convergence is not established.

    Covariance-based normal estimation methods, commonly used for point clouds (e.g.\ \cite{mitra:2003-acm}),
    constitute another popular approach. These methods rely on local covariance analysis and are theoretically
    justified under assumptions of Gaussian noise. However, such assumptions do not hold for digitized shapes,
    whose geometry comes from deterministic grid sampling rather than stochastic perturbations. This mismatch
    makes the application of covariance-based estimators to digital surfaces theoretically less grounded and
    practically less reliable, motivating the need for methods tailored to digital geometry.

    We propose here a normal estimator defined as the most orthogonal
    vector to the cone of visibility at the point of interest.
    Visibility is high in smooth regions and the induced visibility
    vectors are good approximations of tangent vectors. On the contrary
    the visibility is blocked at sharp features, so the normal vector
    is not influenced by the geometry on the other side of the features.
    We demonstrate the superiority of this normal estimator for estimating
    curvatures along digital surfaces with sharp features.

    Note that our algorithm for computing visibility is in fact much
    more general. The same algorithm could be used to recognize if any
    pattern of lattice points is present on a shape. It is similar to
    an erosion algorithm where the structuring element is the chosen
    pattern, and could also be used for morphological operations~\cite{soille1999morphological}.
    The paper outline is as follows. In Section~2, we recall some
    definitions and present tangency of chords and its equivalence
    to visibility. Section~3 describes the specific data structure
    for encoding set of grid cells, and the main algorithm that
    exploits this encoding to compute visibility exactly. Section~4
    discrete normal estimator, and how it improves curvature estimates
    on digital surfaces. Section~5 provides proofs of the convergence
    of this normal estimator on smooth surfaces. Finally, Section 6
    concludes and gives some perspectives to this work.
    %% , notably other usages of this algorithm in the field.

%    \deleted[id=JO]{
%    Visibility is a fundamental concept in computational geometry and digital topology, with applications ranging from computer vision to geometric modeling and computer graphics.
%    In this work, we explore visibility through the lens of chord tangency, introducing a novel approach that builds on discrete geometric structures.
%    Our framework leverages the discrete setting of and cell complexes, providing a rigorous foundation for analyzing visibility properties in digital spaces.
%    }
%
%
%    \deleted[id=JO]{
%    We recall essential definitions from previous works, particularly the notions of cell complexes and the star operator as formalized in~\cite{lachaud:2021-dgmm} and~\cite{lachaud:2022-jmiv}.
%    The integer grid serves as our primary space of study, where geometric structures are discretized using cell complexes.
%    A cell complex is a decomposition of space into elementary units (vertices, edges, faces, and higher-dimensional counterparts) forming a combinatorial representation of geometric objects.
%    The star of a cell, as defined in these works, consists of all higher-dimensional cells that contain it, a crucial concept for analyzing local neighborhoods and connectivity.
%    }
%
%    \deleted[id=JO]{
%      Building on these foundations, our study focuses on visibility as determined by the tangency of chords in discrete geometry.
%    We define and analyze how visibility relationships emerge in this context and investigate their combinatorial and topological implications.
%    This approach provides a new perspective on discrete visibility, offering potential applications in digital imaging, surface reconstruction, and computational topology.
%    }
%
%    \deleted[id=JO]{
%      The remainder of this paper is structured as follows.
%    In Section 2, we formalize the concept of chord tangency and its role in visibility analysis.
%    Section 3 enters into the usage of integer intervals intersections to quickly scan the figure in order to recover this visibiltiy.
%    Section 4 presents our main results, using this visibility to compute normals using the CNC estimator~\cite{lachaud:2022-dcg}.
%    Finally, Section 5 concludes with some other applications of integer intervals intersections in the field.
%    }
