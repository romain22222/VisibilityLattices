We have proposed a new algorithm that computes the visibility between
all pairs of points on a digital surface. It uses the specificity of a
structure to represent sets of lattice points or cells, a mapping from
projected coordinates to list of integer intervals. Compared to a
classical breadth-first approach to compute visibility, it provides
the exact visibility result, even when the set of visible points
from a source is disconnected. As shown by experiments the running
times are comparable with the breadth-first algorithm, and even faster
for small maximal visibility distance, which are typical when
processing standard 3d images up to $512^3$. We have used visibility
to define a discrete tangent estimator that respects salient features
while giving good approximations on digitization of smooth parts. The
obtained normal field is more suitable to curvature estimation than
the classical Integral Invariant normal estimator.

We have several ideas for possible future works. First, it is possible
to speed up the identification of non visibility by a coarse-to-fine
approach and a precomputation of a pyramid of covering cells. We would
like to explore if we can build such a pyramid variant of our
algorithm, considering the primitive vectors as a hierarchy. \deleted[id=ROM]{Second we
would like to prove the muligrid convergence of our normal estimator,
which is observable on experiments.} Last, our algorithm is not limited
to pairwise visibility, but is more an algorithm of exact pattern
matching. We would like to explore new applications of pattern
identification along digital surfaces (like corner detection, locally
convex zones identification, etc.).
